{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#(https://github.com/kiengiv/TripAdvisorPython/blob/master/Script_Hotel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "import pprint\n",
    "import json\n",
    "import argparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating CSV file to be used\n",
    "file = open(os.path.expanduser(r\"~/Desktop/TripAdviser Reviews.csv\"), \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write(b\"Organization,Address,Reviewer,Review Title,Review,Review Count,Help Count,Attraction Count,Restaurant Count,Hotel Count,Location,Rating Date,Rating\" + b\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List the first page of the reviews (ends with \"#REVIEWS\") - separate the websites with ,\n",
    "WebSites = [\"https://www.tripadvisor.ca/Hotel_Review-g154918-d182313-Reviews-Marmot_Lodge-Jasper_Jasper_National_Park_Alberta.html#REVIEWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Checker = \"REVIEWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looping through each site until it hits a break\n",
    "for theurl in WebSites:\n",
    "    thepage = urllib.request.urlopen(theurl)\n",
    "    soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "    while True:\n",
    "        # extract the help count, restaurant review count, attraction review count and hotel review count\n",
    "        a = b = 0\n",
    "        helpcountarray = restaurantarray = attractionarray = hotelarray = \"\"\n",
    "\n",
    "        for profile in soup.findAll(attrs={\"class\": \"memberBadging g10n\"}):\n",
    "            image = profile.text.replace(\"\\n\", \"|||||\").strip()\n",
    "            if image.find(\"helpful vote\") > 0:\n",
    "                counter = image.split(\"helpful vote\", 1)[0].split(\"|\", 1)[1][-4:].replace(\"|\", \"\").strip()\n",
    "                if len(helpcountarray) == 0:\n",
    "                    helpcountarray = [counter]\n",
    "                else:\n",
    "                    helpcountarray.append(counter)\n",
    "            elif image.find(\"helpful vote\") < 0:\n",
    "                if len(helpcountarray) == 0:\n",
    "                    helpcountarray = [\"0\"]\n",
    "                else:\n",
    "                    helpcountarray.append(\"0\")\n",
    "\n",
    "            if image.find(\"attraction\") > 0:\n",
    "                counter = image.split(\"attraction\", 1)[0].split(\"|\", 1)[1][-4:].replace(\"|\", \"\").strip()\n",
    "                if len(attractionarray) == 0:\n",
    "                    attractionarray = [counter]\n",
    "                else:\n",
    "                    attractionarray.append(counter)\n",
    "            elif image.find(\"attraction\") < 0:\n",
    "                if len(attractionarray) == 0:\n",
    "                    attractionarray = [\"0\"]\n",
    "                else:\n",
    "                    attractionarray.append(\"0\")\n",
    "\n",
    "            if image.find(\"restaurant\") > 0:\n",
    "                counter = image.split(\"restaurant\", 1)[0].split(\"|\", 1)[1][-4:].replace(\"|\", \"\").strip()\n",
    "                if len(restaurantarray) == 0:\n",
    "                    restaurantarray = [counter]\n",
    "                else:\n",
    "                    restaurantarray.append(counter)\n",
    "            elif image.find(\"restaurant\") < 0:\n",
    "                if len(restaurantarray) == 0:\n",
    "                    restaurantarray = [\"0\"]\n",
    "                else:\n",
    "                    restaurantarray.append(\"0\")\n",
    "\n",
    "            if image.find(\"hotel\") > 0:\n",
    "                counter = image.split(\"hotel\", 1)[0].split(\"|\", 1)[1][-4:].replace(\"|\", \"\").strip()\n",
    "                if len(hotelarray) == 0:\n",
    "                    hotelarray = [counter]\n",
    "                else:\n",
    "                    hotelarray.append(counter)\n",
    "            elif image.find(\"hotel\") < 0:\n",
    "                if len(hotelarray) == 0:\n",
    "                    hotelarray = [\"0\"]\n",
    "                else:\n",
    "                    hotelarray.append(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the rating count for each user review\n",
    "        altarray = \"\"\n",
    "        for rating in soup.findAll(attrs={\"class\": \"rating reviewItemInline\"}):\n",
    "            alt = rating.find('img', alt=True)['alt']\n",
    "            if alt[-5:] == 'stars':\n",
    "                if len(altarray) == 0:\n",
    "                    altarray = [alt]\n",
    "                else:\n",
    "                    altarray.append(alt)\n",
    "\n",
    "        Organization = soup.find(attrs={\"class\": \"heading_name\"}).text.replace('\"', ' ').replace('Review of',\n",
    "                                                                                                 ' ').strip()\n",
    "        Address = soup.findAll(attrs={\"class\": \"format_address\"})[0].text.replace(',', '').replace('\\n', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through each review on the page\n",
    "        for x in range(0, len(hotelarray)):\n",
    "            try:\n",
    "                Reviewer = soup.findAll(attrs={\"class\": \"username mo\"})[x].text\n",
    "            except:\n",
    "                Reviewer = \"N/A\"\n",
    "                continue\n",
    "\n",
    "            Reviewer = Reviewer.replace(',', ' ').replace('”', '').replace('“', '').replace('\"', '').strip()\n",
    "            ReviewCount = soup.findAll(attrs={\"class\": \"reviewerBadge badge\"})[x].text.split(' ', 1)[0].strip()\n",
    "            Location = soup.findAll(attrs={\"class\": \"location\"})[x].text.replace(',', ' ').strip()\n",
    "            ReviewTitle = soup.findAll(attrs={\"class\": \"quote\"})[x].text.replace(',', ' ').replace('”', '').replace('“','').replace('\"', '').replace('é', 'e').strip()\n",
    "            Review = soup.findAll(attrs={\"class\": \"entry\"})[x].text.replace(',', ' ').replace('\\n', ' ').strip()\n",
    "            RatingDate = soup.findAll(attrs={\"class\": \"ratingDate\"})[x].text.replace('Reviewed', ' ').replace('NEW',' ').replace(',', ' ').strip()\n",
    "            Rating = altarray[x][:1]\n",
    "            HelpCount = helpcountarray[x]\n",
    "            AttractionCount = attractionarray[x]\n",
    "            Restaurant = restaurantarray[x]\n",
    "            Hotel = hotelarray[x]\n",
    "\n",
    "            Record = Organization + \",\" + Address + \",\" + Reviewer + \",\" + ReviewTitle + \",\" + Review + \",\" + ReviewCount + \",\" + HelpCount + \",\" + AttractionCount + \",\" + Restaurant + \",\" + Hotel + \",\" + Location + \",\" + RatingDate + \",\" + Rating\n",
    "            if Checker == \"REVIEWS\":\n",
    "                file.write(bytes(Record, encoding=\"ascii\", errors='ignore')  + b\"\\n\")\n",
    "\n",
    "        link = soup.find_all(attrs={\"class\": \"nav next rndBtn ui_button primary taLnk\"})\n",
    "        print(Organization)\n",
    "        if len(link) == 0:\n",
    "            break\n",
    "        else:\n",
    "            soup = BeautifulSoup(urllib.request.urlopen(\"http://www.tripadvisor.com\" + link[0].get('href')),\"html.parser\")\n",
    "            print(link[0].get('href'))\n",
    "            Checker = link[0].get('href')[-7:]\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_4; en-US) AppleWebKit/534.3 (KHTML, like Gecko) Chrome/6.0.472.63 Safari/534.3'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "ta_url = 'http://www.tripadvisor.ca'\n",
    "base_url = 'https://www.tripadvisor.ca/Tourism-g154917-'\n",
    "location_url = 'Jasper_National_Park_Alberta-Vacations.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    activities = []\n",
    "\n",
    "    dl_page_src(base_url + location_url)\n",
    "\n",
    "    with open('tripadvisor.html', encoding='utf-8') as page_src:\n",
    "        source = page_src.read()\n",
    "\n",
    "    soup = BeautifulSoup(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-48be431fb430>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-48be431fb430>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    for page_no in range(page_count):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # get the lazy loaded image list\n",
    "image_list = get_image_list(soup)\n",
    "    \n",
    "    # get last element in the pagenation (i.e.: total number of pages)\n",
    "page_count = int(soup.select('.pagination a')[-1].text.strip())\n",
    "    for page_no in range(page_count):\n",
    "        # our formula to compute the next url to download:\n",
    "        # [page_no * 30]\n",
    "        # page 1: base_url + location_url\n",
    "        # page 2: base_url + 'oa' + [page_no * 30] + '-' + location_url\n",
    "        # etc ...\n",
    "        page_results = soup.select('#FILTERED_LIST .attraction_element')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.tripadvisor.ca/Attractions-g155019-Activities-Toronto_Ontario.html\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a5d1be1b1a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-a5d1be1b1a57>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# loop over all elements and extract the useful data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.property_title a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mrating_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.rate_no'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_4; en-US) AppleWebKit/534.3 (KHTML, like Gecko) Chrome/6.0.472.63 Safari/534.3'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "ta_url = 'http://www.tripadvisor.ca'\n",
    "base_url = 'http://www.tripadvisor.ca/Attractions-g155019-Activities-'\n",
    "location_url = 'Toronto_Ontario.html'\n",
    "\n",
    "def main():\n",
    "    activities = []\n",
    "\n",
    "    dl_page_src(base_url + location_url)\n",
    "\n",
    "    with open('tripadvisor.html', encoding='utf-8') as page_src:\n",
    "        source = page_src.read()\n",
    "\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    \n",
    "    # get the lazy loaded image list\n",
    "    image_list = get_image_list(soup)\n",
    "    \n",
    "    # get last element in the pagenation (i.e.: total number of pages)\n",
    "    page_count = int(soup.select('.pagination a')[-1].text.strip())\n",
    "    for page_no in range(page_count):\n",
    "        # our formula to compute the next url to download:\n",
    "        # [page_no * 30]\n",
    "        # page 1: base_url + location_url\n",
    "        # page 2: base_url + 'oa' + [page_no * 30] + '-' + location_url\n",
    "        # etc ...\n",
    "        page_results = soup.select('#FILTERED_LIST .attraction_element')\n",
    "\n",
    "        # loop over all elements and extract the useful data\n",
    "        for result in page_results:\n",
    "            title = result.select('.property_title a')[0].text.strip()\n",
    "            \n",
    "            rating_obj = result.select('.rate_no')\n",
    "            pattern = re.compile('\\srate_no\\sno(\\d{2})\"')\n",
    "            matches = pattern.search(str(rating_obj))\n",
    "            if matches:\n",
    "                print(matches.group(1))\n",
    "                rating = matches.group(1)\n",
    "                total_reviews = result.select('.rating .more a')[0].text.strip().replace(' reviews', '')\n",
    "            else:\n",
    "                rating = '0'\n",
    "                total_reviews = '0'\n",
    "            \n",
    "            popularity = result.select('.popRanking')[0].text.strip()\n",
    "            review_url = ta_url + result.select('a.photo_link')[0]['href']\n",
    "            \n",
    "            # get image url\n",
    "            lazy_load_obj = result.select('.photo_booking a img')\n",
    "            if lazy_load_obj[0].has_attr('id'):\n",
    "                lazy_load_id = lazy_load_obj[0]['id']\n",
    "                image_obj = [x['data'] for x in image_list if x['id'] == lazy_load_id]\n",
    "                image_url = image_obj[0]\n",
    "            else:\n",
    "                image_url = 'static/images/generic.jpg'\n",
    "            \n",
    "            activities.append({\n",
    "                'title': title,\n",
    "                'rating': rating,\n",
    "                'reviews': total_reviews,\n",
    "                'popularity': popularity,\n",
    "                'review_url': review_url,\n",
    "                'image_url': image_url\n",
    "            })\n",
    "\n",
    "        # compute the url for the next page\n",
    "        next_page = base_url + 'oa' + str((page_no + 1) * 30) + '-' + location_url\n",
    "\n",
    "        time.sleep(15)\n",
    "        dl_page_src(next_page)\n",
    "        \n",
    "        with open('tripadvisor.html', encoding='utf-8') as page_src:\n",
    "            source = page_src.read()\n",
    "            \n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "        \n",
    "        # get the lazy loaded image list\n",
    "        image_list = get_image_list(soup)\n",
    "\n",
    "    with open('activities.json', 'w', encoding='utf-8') as output:\n",
    "        output.write(json.dumps(activities, indent=4))\n",
    "\n",
    "def dl_page_src(url):\n",
    "    print(url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    with open('tripadvisor.html', 'w', encoding='utf-8') as saved_page:\n",
    "        saved_page.write(soup.prettify(encoding='utf-8').decode('utf-8'))\n",
    "        \n",
    "def get_image_list(soup):\n",
    "    # get all the script tags then get the one that contains the line\n",
    "    # 'var lazyImgs'\n",
    "    script_tags = soup.find_all('script')\n",
    "    pattern = re.compile('var\\s*?lazyImgs\\s*?=\\s*?(\\[.*?\\]);', re.DOTALL)\n",
    "    \n",
    "    for tag in script_tags:\n",
    "        matches = pattern.search(tag.text)    \n",
    "        if matches:\n",
    "            image_list = json.loads(matches.group(1))\n",
    "            return image_list\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
