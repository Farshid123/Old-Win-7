{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "theText = \"No food is good food. Ha. I am on a diet and the food is awful and lame. How bad I am!\"\n",
    "positiveWords=['awesome','good','nice','super','fun','delightful']\n",
    "negativeWords=['awful','lame','horrible','bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positiveWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(positiveWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function takes a text and tokenizes it into a list of sentences\n",
    "def tokenSentences(textIn):\n",
    "    theSentences = sent_tokenize(theText)\n",
    "    return theSentences\n",
    "\n",
    "# Test how many sentences we get\n",
    "len(tokenSentences(theText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'food', 'is', 'good', 'food']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(txt2Token): # Function for tokenizing\n",
    "    theTokens = re.findall(r'\\b\\w[\\w-]*\\b', txt2Token.lower())\n",
    "    return theTokens\n",
    "    \n",
    "# We test if the function works with the first sentnece from the list above\n",
    "tokensOfSent = tokenizer(tokenSentences(theText)[0])\n",
    "print(tokensOfSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['good']\n"
     ]
    }
   ],
   "source": [
    "# Function that counts how many target words are in a list of tokens\n",
    "def countSentimentalTokens(listOfTokens,listOfTargetWords):\n",
    "    numTargetWords = 0\n",
    "    matchedWords = []\n",
    "    for token in listOfTokens: # Goes through the tokens in the list\n",
    "        if token in listOfTargetWords: # For each one it checks if it is in the target list\n",
    "            numTargetWords += 1\n",
    "            matchedWords.append(token)\n",
    "    return numTargetWords, matchedWords # Note that we are returning a tuple (2 values)\n",
    "\n",
    "theTuple = countSentimentalTokens(tokensOfSent,positiveWords)\n",
    "print(str(theTuple[0]) + \" \" + str(theTuple[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 20%  Negative: 0%\n"
     ]
    }
   ],
   "source": [
    "def calculatePercent(listOfTokens,positiveList,negativeList):\n",
    "    numWords = len(listOfTokens) # How many words total\n",
    "    \n",
    "    # We call the function to count the tokens from the positive list in the sentence\n",
    "    positiveMatches = countSentimentalTokens(listOfTokens,positiveList) \n",
    "    percntPos = positiveMatches[0] / numWords # We divide by the total number of words for percentage\n",
    "    \n",
    "    # We call the function to count the tokens from the negative list in the sentence\n",
    "    negativeMatches = countSentimentalTokens(listOfTokens,negativeList)\n",
    "    percntNeg = negativeMatches[0] / numWords # We divide by the total number of words for percentage\n",
    "\n",
    "    return percntPos, percntNeg # We return the percentage of positive and negative words\n",
    "\n",
    "# We test the function on the first sentence\n",
    "results = calculatePercent(tokensOfSent,positiveWords,negativeWords)\n",
    "print(\"Positive: \" + \"{:.0%}\".format(results[0]) + \"  Negative: \" + \"{:.0%}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokensOfSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateSentiment(percntPos,percntNeg):\n",
    "    sentiment = percntPos - percntNeg # Subtract the percentage of negative words from positive words\n",
    "    return sentiment\n",
    "\n",
    "# Test what we get\n",
    "calculateSentiment(results[0],results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.0, -0.16666666666666666, -0.25]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processText(textIn,posMatchWords,negMatchWords):\n",
    "    listOfSentences = tokenSentences(textIn) # Tokenize the text\n",
    "    \n",
    "    listOfSentiments = []\n",
    "    for sentence in listOfSentences: # Process sentence by sentence\n",
    "        sentTokens = tokenizer(sentence) # Tokenize the sentences\n",
    "        percentages = calculatePercent(sentTokens,posMatchWords,negMatchWords) # Calculates percents\n",
    "        theSentiment = calculateSentiment(percentages[0],percentages[1]) # Calculates sentiment\n",
    "        listOfSentiments.append(theSentiment) # Appends sentiment to list\n",
    "        \n",
    "    return listOfSentiments # Return the final list\n",
    "\n",
    "# Test the function\n",
    "theFinalList = processText(theText,positiveWords,negativeWords)\n",
    "theFinalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(positiveWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
